{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 08. CNN(Convolutional Neural Network) 합성곱 신경망\n",
    "- 이미지 처리에 탁월\n",
    "- Convolution layer(합성곱층) + Pooling layer(풀링층)\n",
    "- Convolution layer : CONV(합성곱 연산) + 활성화 함수\n",
    "    - 합성곱 연산을 통해 이미지의 특징을 추출\n",
    "    - kernel 또는 filter라는 n * m 행렬로 높이 * 너비 크기의 이미지를 처음부터 끝까지 겹치며 훑어 n * m 크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것\n",
    "        - 행렬의 곱\n",
    "    - 왼쪽 위부터 오른쪽까지 순차적으로 진행\n",
    "        - 일반적으로 3 * 3 혹은 5 * 5 사용 (이동범위를 stride(스트라이드)라고 함.\n",
    "    - 결과를 feature map(특성맵)이라고 함.\n",
    "    \n",
    "- Pooling layer : POOL(풀링 연산)\n",
    "- 다층 퍼셉트론으로 분류한다고 하면 저차원으로 변환 되면서 공간적 구조(spatial structure) 정보가 유실됨 \n",
    "        -> 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법 필요\n",
    "        -> 이를 위해 사용하는 것이 합성곱 신경망\n",
    "- 이미지 처리의 기본적인 용어 정리\n",
    "    - 채널\n",
    "        - 기계는 글자 또는 이미지보다 숫자(텐서)를 더 잘 처리함.\n",
    "        - 이미지는 높이 * 너비 * 채널 의 3차원 텐서\n",
    "                - 높이: 이미지의 세로 방향 픽셀수\n",
    "                - 너비: 이미지의 가로 방향 픽셀수\n",
    "                - 채널: 색 성분\n",
    "                        - 흑백 이미지 채널 1\n",
    "                        - 0 ~ 255 사잇값\n",
    "                        - 컬러 이미지 채널 3 적, 녹, 청\n",
    "                        - 높이 28 너비 28 컬러인 이미지는 28 * 28 * 3의 3차원 텐서\n",
    "    - 패딩\n",
    "        - 입력과 특성맵의 크기를 동일하게 유지되도록 하고싶을 떄 사용\n",
    "                - 입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가\n",
    "                - 주로 값을 0으로 채우는 제로 패딩(zero padding) 사용\n",
    "  \n",
    "    - 가중치\n",
    "        - 다중 퍼셉트론 3 * 3 이미지 처리\n",
    "                - 1차원 텐서인 벡터로 -> 3 * 3 = 9\n",
    "                        - 입력층 9개의 뉴런을 가짐\n",
    "                - 4개의 뉴런을 가지는 은닉층 추가 \n",
    "                - 9 * 4 =36 36개의 가중치를 가짐\n",
    "                        \n",
    "        - 합성곱 신경망 3 * 3 이미지 처리\n",
    "                - 2 * 2 커널 사용 스트라이드 1\n",
    "                - 합성곱 신경망에서의 가중치는 커널 행렬의 원소\n",
    "                - 결국 합성곱 신경망은 커널의 수 만큼만 가중치 사용 -> 4개\n",
    "                - 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용\n",
    "                == 합성곱 신경망은 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존\n",
    "                - 비선형성 추가를 위해서 활성화 함수를 지나게 되는데 이때 렐루 함수나 렐루 함수의 변형들이 주로 사용됨\n",
    "                - 비선형성은 모델이 더 복잡한 함수를 학습할 수 있게 해주며, 따라서 더 복잡한 패턴과 관계를 데이터에서 학습할 수 있게 됨. 활성화 함수 없이는 여러 층을 쌓는 것이 의미가 없음. 왜냐하면 선형 연산의 연속은 궁극적으로 단일 선형 연산으로 간소화될 수 있기 때문. 즉, 활성화 함수 없이 다층 구조를 가지는 것은 그저 하나의 선형 모델을 사용하는 것과 다름이 없음. ReLU는 특정 음수 값을 모두 0으로 만들어주는 비선형성을 가지고 있어서 계산 효율성과 학습 속도에서 장점을 가지고 시그모이드나 탄젠트 하이퍼볼릭은 출력값의 범위를 -1과 1 사이, 또는 0과 1 사이로 제한하여 모델이 출력을 해석하기 쉽게 만들어줌.\n",
    "                        \n",
    "    - 편향\n",
    "        - 하나의 값만 존재하며, 커널이 적용된 결과의 모든 원소에 더해짐.\n",
    "\n",
    "- 특성 맵의 크기 계산\n",
    "    - https://wikidocs.net/62306 6번\n",
    "\n",
    "- 다수의 채널을 가질 경우의 합성곱 연산(3차원 텐서의 합성곱 연산)\n",
    "    - 실제로 합성곱 연산의 입력은 '다수의 채널을 가진' 이미지 또는 이전 연산의 결과로 나온 특성 맵일 수 있다.\n",
    "    - 다수의 채널을 가진 입력 데이터를 가지고 합성곱 연산을 한다고 하면 커널의 채널 수도 입력의 채널 수만큼 존재해야 한다. \n",
    "    - 입력 데이터의 채널 수와 커널의 채널 수는 같아야 한다. \n",
    "    - 채널 수가 같으므로 합성곱 연산을 채널마다 수행하고, 그 결과를 모두 더하여 최종 특성 맵을 얻는다.(행렬의 덧셈)\n",
    "    - 합성곱 연산의 결과로 얻은 특성 맵의 채널 차원은 RGB 채널 등과 같은 컬러의 의미를 담고 있지는 않다.\n",
    "        \n",
    "- 3차원 텐서의 합성곱 연산\n",
    "    - 3차원 입력 데이터는 종일한 채널 수를 가지는 커널과 합성곱 연산하여 특성맵을 얻음\n",
    "    - 다수의 커널을 사용하는 경우 사용한 커널 수가는 합성곱 연산의 결과로 나오는 특성 맵의 채널 수가 됨.\n",
    "    - 가중치 매개변수의 총 개수\n",
    "        - 가중치는 커널의 원소 하나의 커널의 하나의 채널은 커널의 높이 * 커널의 너비 개의 매개변수를 가지고 있음.\n",
    "        - 합성곱 연사늘 하려면 커널은 입력 뎅터의 채널 수와동일한 채널 수를 가져야 함. -> 하나의 커널이 가지는 매개 변수의 수는 커널의 높이 * 커널의 너비 * 입력 데이터의 채널\n",
    "        - 이런 커널이 총 n개가 있어야 하므로 가중치 매개변수의 총 수는\n",
    "                - 커널의 높이 * 커널의 너비 * 입력 데이터의 채널 * n\n",
    "\n",
    "- 풀링\n",
    "    - 일반적으로 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적. \n",
    "    - 풀링 층에서는 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 풀링 연산이 이루어짐. \n",
    "    - 풀링 연산에는 일반적으로 최대 풀링(max pooling)과 평균 풀링(average pooling)이 사용\n",
    "    - 풀링 연산은 커널과 스트라이드 개념이 존재한다는 점에서 합성곱 연산과 유사하지만, 합성곱 연산과의 차이점은 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않음."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f3657b089871a83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN을 통한 MNIST 분류\n",
    "1. 모델 이해\n",
    "   1. 첫번째 표기 방법\n",
    "        합성곱(nn.Cov2d) + 활성화 함수(nn.ReLU)를 하나의 합성곱 층으로 보고, 맥스풀링(nn.MaxPoold2d)은 풀링 층으로 별도로 명명.\n",
    "   2. 합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU) + 맥스풀링(nn.MaxPoold2d)을 하나의 합성곱 층으로 본다.\n",
    "   \n",
    "- 1번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "- 2번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "- 3번 레이어 : 전결합층(Fully-Connected layer)\n",
    "특성맵을 펼친다. # batch_size × 7 × 7 × 64 → batch_size × 3136\n",
    "전결합층(뉴런 10개) + 활성화 함수 Softmax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e16590554529c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# conda 프롬프트 관리자 권한으로 설치\n",
    "# conda install pytorch torchvision torchaudio cpuonly -c pytorch "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:21:39.419818500Z",
     "start_time": "2024-03-21T02:21:39.416040400Z"
    }
   },
   "id": "1c84e5af18e3a769",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:21:39.972594500Z",
     "start_time": "2024-03-21T02:21:39.968744500Z"
    }
   },
   "id": "3b99db6067572515",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "print('tensor size: {}'.format(inputs.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:28:39.940821300Z",
     "start_time": "2024-03-21T02:28:39.929040Z"
    }
   },
   "id": "6e8e5529cd8b4657",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합성곱층, 풀링 선언\n",
    "# 1채널 in, 32채널 out, 커널 3, 패딩 1\n",
    "conv1 = nn.Conv2d(1, 32, 3, padding= 1)\n",
    "conv1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:28:40.414074Z",
     "start_time": "2024-03-21T02:28:40.407337Z"
    }
   },
   "id": "a18baaf1cbe5b429",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = nn.Conv2d(32, 64, kernel_size= 3, padding= 1)\n",
    "conv2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:28:40.847352800Z",
     "start_time": "2024-03-21T02:28:40.843352100Z"
    }
   },
   "id": "97221dc3a7ccf269",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맥스풀링\n",
    "pool = nn.MaxPool2d(2, 2) # 정수 하나 인자로 넣으면 커널 사이즈와 스트라이드가 둘 다 해당 값으로 지정\n",
    "# pool = nn.MaxPool2d(2)\n",
    "pool"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:28:41.294687900Z",
     "start_time": "2024-03-21T02:28:41.289367800Z"
    }
   },
   "id": "28a7f46d9f9006d8",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32, 28, 28])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구현체 연결을 통한 모델 생성\n",
    "# 입력을 첫번째 합성곱층을 통과시키고 합성곱층을 통과시킨 후의 텐서의 크기 확인\n",
    "out = conv1(inputs)\n",
    "out.shape\n",
    "# 32채널의 28너비 28높이의 텐서가 됨. 32가 나온 이유는 conv1의 out_channel로 32를 지정해주었기 때문. 또한, 28너비 28높이가 된 이유는 패딩을 1폭으로 하고 3 × 3 커널을 사용하면 크기가 보존되기 때문"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:46.732286400Z",
     "start_time": "2024-03-21T02:41:46.724529300Z"
    }
   },
   "id": "ea9cc57b2e532ee7",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32, 14, 14])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기 확인\n",
    "out = pool(out)\n",
    "out.shape\n",
    "# 32채널 14너비 14높이 텐서 생성"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:47.967333Z",
     "start_time": "2024-03-21T02:41:47.946375Z"
    }
   },
   "id": "226d2e4dc163e01",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64, 14, 14])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  두번째 합성곱층에 통과시키고 통과한 후의 텐서의 크기 확인\n",
    "out = conv2(out)\n",
    "out.shape\n",
    "# 64채널의 14너비 14높이의 텐서 생성. 64가 나온 이유는 conv2의 out_channel로 64를 지정해주었기 때문. 또한, 14너비 14높이가 된 이유는 패딩을 1폭으로 하고 3 × 3 커널을 사용하면 크기가 보존되기 때문"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:49.527154800Z",
     "start_time": "2024-03-21T02:41:49.521926700Z"
    }
   },
   "id": "f83ca1d18c25b045",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64, 7, 7])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기 확인\n",
    "out = pool(out)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:50.391027500Z",
     "start_time": "2024-03-21T02:41:50.380616800Z"
    }
   },
   "id": "3428f282012524b0",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 n번째 차원을 접근하게 해주는 .size(n)\n",
    "# 현재 out의 크기는 1 × 64 × 7 × 7 \n",
    "# out의 첫번째 차원이 몇인지 출력\n",
    "out.size(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:51.433396200Z",
     "start_time": "2024-03-21T02:41:51.413216900Z"
    }
   },
   "id": "ab59a6c3bfe74719",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:52.293528300Z",
     "start_time": "2024-03-21T02:41:52.284862200Z"
    }
   },
   "id": "1362f171947f2e0e",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:52.960470400Z",
     "start_time": "2024-03-21T02:41:52.955026100Z"
    }
   },
   "id": "bf656d7c011e7f3d",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:53.663457400Z",
     "start_time": "2024-03-21T02:41:53.656143600Z"
    }
   },
   "id": "38457bac6a0dbcf6",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3136])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 펼치기\n",
    "# .view()를 사용\n",
    "# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼치기\n",
    "out = out.view(out.size(0), -1)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:54.417Z",
     "start_time": "2024-03-21T02:41:54.412506400Z"
    }
   },
   "id": "ae49791370588ccf",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 차원을 제외하고 모두 하나의 차원으로 통합 - 평탄화(flatten)\n",
    "# 전결합층(Fully-Connteced layer = 밀집층(Dense Layer))를 통과\n",
    "# 출력층으로 10개의 뉴런을 배치하여 10개 차원의 텐서로 변환\n",
    "# 전결합층이 10개의 출력 뉴런을 가지고 있으며, 결과적으로 모델의 최종 출력이 10차원 벡터가 되도록 한다는 의미. 이는 일반적으로 10개의 다른 클래스를 가진 분류 문제에서 각 클래스에 대한 예측 확률을 나타내는 경우에 해당. 예를 들어, 손글씨 숫자 인식(MNIST) 문제에서는 0부터 9까지 10개의 숫자 클래스가 있으므로, 최종 출력층에 10개의 뉴런을 배치\n",
    "fc = nn.Linear(3136, 10) # input_dim = 3,136, output_dim = 10\n",
    "out = fc(out)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:41:55.254277700Z",
     "start_time": "2024-03-21T02:41:55.246371Z"
    }
   },
   "id": "c517c31058383291",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# CNN으로 MNIST 분류하기\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:43:31.786011900Z",
     "start_time": "2024-03-21T02:43:29.976852Z"
    }
   },
   "id": "dc4d1babd905b179",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1f26adf4af0>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:46:02.361893600Z",
     "start_time": "2024-03-21T02:46:02.345671100Z"
    }
   },
   "id": "5ea839328d180441",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T05:31:43.090829600Z",
     "start_time": "2024-03-21T05:31:43.068553900Z"
    }
   },
   "id": "f6608174bbaed574",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 데이터셋 정의 by 데이터로더\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T02:48:40.439003100Z",
     "start_time": "2024-03-21T02:48:40.385472100Z"
    }
   },
   "id": "de7e77fa0822f4eb",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 데이터로더 - 배치 크기 지정\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T04:49:10.977984500Z",
     "start_time": "2024-03-21T04:49:10.973287800Z"
    }
   },
   "id": "aab12824ffad359e",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째층\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 두번째층\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T04:49:24.437167700Z",
     "start_time": "2024-03-21T04:49:24.406474Z"
    }
   },
   "id": "5783e95a32a284a6",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = CNN().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T04:50:07.696020200Z",
     "start_time": "2024-03-21T04:50:07.670815800Z"
    }
   },
   "id": "75024230b9e5e3c3",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T05:30:17.652802400Z",
     "start_time": "2024-03-21T05:30:17.626378100Z"
    }
   },
   "id": "baee650f85d38552",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T05:30:27.231149Z",
     "start_time": "2024-03-21T05:30:27.210327400Z"
    }
   },
   "id": "214be446f93e7fad",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.216004267\n",
      "[Epoch:    2] cost = 0.0624041557\n",
      "[Epoch:    3] cost = 0.0444612838\n",
      "[Epoch:    4] cost = 0.035598442\n",
      "[Epoch:    5] cost = 0.0291232895\n",
      "[Epoch:    6] cost = 0.025439417\n",
      "[Epoch:    7] cost = 0.0200062394\n",
      "[Epoch:    8] cost = 0.01774\n",
      "[Epoch:    9] cost = 0.0149350027\n",
      "[Epoch:   10] cost = 0.0121499421\n",
      "[Epoch:   11] cost = 0.0103771975\n",
      "[Epoch:   12] cost = 0.00844045635\n",
      "[Epoch:   13] cost = 0.00701702852\n",
      "[Epoch:   14] cost = 0.00606769836\n",
      "[Epoch:   15] cost = 0.00525440834\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T05:37:11.318998100Z",
     "start_time": "2024-03-21T05:31:53.759334100Z"
    }
   },
   "id": "6d41f7cf5e063f0f",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9850000143051147\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()를 사용하여 자동 미분을 비활성화\n",
    "with torch.no_grad():\n",
    "    # mnist_test.test_data 대신 mnist_test.data 사용\n",
    "    # mnist_test.test_labels 대신 mnist_test.targets 사용\n",
    "    X_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.targets.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T06:09:45.166731900Z",
     "start_time": "2024-03-21T06:09:43.426216400Z"
    }
   },
   "id": "df07da30c43f2215",
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep CNN을 통한 MNIST 분류\n",
    "모델의 아키텍처는 총 5개의 층으로 구성. 앞서 만든 모델에서 1번 레이어와 2번 레이어는 동일하되, 새로운 합성곱층과 전결합층을 추가\n",
    "\n",
    "- 1번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "- 2번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "- 3번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 64, out_channel = 128, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "- 4번 레이어 : 전결합층(Fully-Connected layer)\n",
    "특성맵을 펼친다. # batch_size × 4 × 4 × 128 → batch_size × 2048\n",
    "전결합층(뉴런 625개) + 활성화 함수 ReLU\n",
    "\n",
    "- 5번 레이어 : 전결합층(Fully-Connected layer)\n",
    "전결합층(뉴런 10개) + 활성화 함수 Softmax\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf7377cf51bf782e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n",
      "[Epoch:    1] cost = 0.185679048\n",
      "[Epoch:    2] cost = 0.0497652404\n",
      "[Epoch:    3] cost = 0.0351733118\n",
      "[Epoch:    4] cost = 0.0297785141\n",
      "[Epoch:    5] cost = 0.0224700067\n",
      "[Epoch:    6] cost = 0.0199470297\n",
      "[Epoch:    7] cost = 0.016308412\n",
      "[Epoch:    8] cost = 0.014568653\n",
      "[Epoch:    9] cost = 0.0133384177\n",
      "[Epoch:   10] cost = 0.0108114965\n",
      "[Epoch:   11] cost = 0.00895884912\n",
      "[Epoch:   12] cost = 0.00957193412\n",
      "[Epoch:   13] cost = 0.00909295026\n",
      "[Epoch:   14] cost = 0.00855032634\n",
      "[Epoch:   15] cost = 0.00729139242\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(0)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                         download=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# 모델 정의\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 총 배치의 수\n",
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "# 총 배치 수 600, 배치 크기 100 훈련데이터는 총 60000개\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T06:24:30.566678800Z",
     "start_time": "2024-03-21T06:16:23.231095400Z"
    }
   },
   "id": "6ed4113edcd27550",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9650999903678894\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "# 학습을 진행하지 않을 것 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T06:26:21.490958800Z",
     "start_time": "2024-03-21T06:26:19.085298Z"
    }
   },
   "id": "b8bc85ecb135bbbf",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "층을 더 깊게 쌓았는데 오히려 정확도가 줄어들었음. \n",
    "결국 층을 깊게 쌓는 것도 중요하지만, 꼭 깊게 쌓는 것이 정확도를 올려주지는 않으며 효율적으로 쌓는 것도 중요하다는 의미."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "961fe9f2b2025e21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4fa0d898e37c03f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
